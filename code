from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date

# Initialize Spark session
spark = SparkSession.builder.appName("ETL_Pipeline").getOrCreate()

# Bronze Layer - raw data
bronze_df = spark.read.csv("SampleSuperstore.csv", header=True, inferSchema=True)
bronze_df.write.mode("overwrite").parquet("bronze_layer/sales_data.parquet")

# Silver Layer - cleaned
silver_df = bronze_df.dropna()
silver_df = silver_df.withColumn("OrderDate", to_date(col("Order Date"), 'MM/dd/yyyy'))
silver_df.write.mode("overwrite").parquet("silver_layer/sales_data.parquet")

# Gold Layer - aggregated KPIs
gold_df = silver_df.groupBy("Region", "Category").sum("Sales", "Profit")
gold_df.write.mode("overwrite").parquet("gold_layer/kpi_data.parquet")

# Show Gold layer
gold_df.show()

